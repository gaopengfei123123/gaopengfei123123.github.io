<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Github-Webhook 小工具]]></title>
    <url>%2F2019%2F11%2F14%2Ftool-github-webhook%2F</url>
    <content type="text"><![CDATA[最近写了一个小工具, 用来接收github webhook消息, 以在服务器上自动执行脚本 gaopengfei123123/hook github hook server一个用来接收webhook的server 环境golang v1.11+ (因为用到了go mod) 安装执行:1go get -u github.com/gaopengfei123123/hook 创建文件 main.go123456789package mainimport ( "github.com/gaopengfei123123/hook")func main() &#123; hook.Execute()&#125; 执行命令1go build -o app main.go app 这个二进制文件就是本体了, 放到合适的地方, 执行:1./app start -d 后台启动, app 同目录下会创建 scripts, logs 两个目录, 和一个 hook.pid 保存pid 检测是否启动:12[root@xxx]# curl localhost:8080/ping&#123;"message":"pong v5"&#125; 说明服务已经启动成功, 服务地址为0.0.0.0:8080 接口 0.0.0.0:8080/ping 检测接口 0.0.0.0:8080/push 接受github webhook请求, 根据 Repository.Name 去判断执行什么脚本 可用指令1234reload 重新加载日志, 以及平滑重启start 启动命令, -d 后台运行stop 终止命令version 程序版本 目录功能: logs 存放请求日志 scripts 存放hook脚本, 当有对应库名的请求进来, 将执行配置好的脚本 hook.pid 存放进程pid 配置文件123456789&#123; "github_hook": &#123; // 以请求消息中的 repository.name 字段来做key "secret": "xxxxxx", // 如果设置了secret则会用这个进行验证, 为空则不验证 "script_path": "", // 脚本所在绝对目录, 为空就是当前的script目录 "event": &#123; "push": "test" // 推送事件执行的脚本 &#125; &#125;&#125; 特性 一键初始化 平滑重启, 信号通信 支持secret验证 异步执行脚本 规避重放 脚本传递参数(TODO) 事件钩子(TODO) 依赖组件 http框架 gin 日志组件 logrus 命令行组件 cobra github地址gaopengfei123123/hook]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>github</tag>
        <tag>hook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转 Go 模仿Unix 管道操作]]></title>
    <url>%2F2019%2F11%2F14%2Fgo-pipe-pattern%2F</url>
    <content type="text"><![CDATA[本文摘录了许式伟 《Go，基于连接与组合的语言》部分内容，为了便于理解，我在其后端写了个完整的示例程序帮助理解，这篇文章 一是展示go在并行编程中的伟大，也是理解和学习闭包的活的教科书 正文让我们从Unix谈起。Go语言与Unix、C语言有着极深的渊源。Go语言的领袖们参与甚至主导了Unix和C语言的设计。Ken Thompson 甚至算得上Unix和C语言的鼻祖。Go语言亦深受Unix和C语言的设计哲学影响。 在Unix世界里，组件就是应用程序（app），每个app可大体抽象为： 输入：stdin（标准输入）, params（命令行参数） 输出：stdout（标准输出） 协议：text (data stream) 不同的应用程序（app）如何连接？答案是：管道（pipeline）。在Unix世界中大家对这样的东西已经很熟悉了：1app1 params1 | app2 params2 通过管道（pipeline），可以将一个应用程序的输出（stdout）转换为另一个应用程序的输入（stdin）。更为神奇的一点，是这些应用程序是并行执行的。app1每产生一段输出，立即会被app2所处理。所以管道（pipeline）称得上是最古老，同时也是极其优秀的并行设施，简单而强大。 需要注意的是，Unix世界中不同应用程序直接是松散耦合的。上游app的输出是xml还是json，下游app需要知晓，但并无任何强制的约束。同一输出，不同的下游app，对协议的理解甚至都可能并不相同。例如，上游app输出一段xml文本，对于某个下游app来说，是一颗dom树，但对linecount程序来说只是一个多行的文本，对于英文单词词频统计程序来说，是一篇英文文章。 为了方便理解，我们先尝试在Go语言中模拟整个Unix的管道（pipeline）机制。首先是应用程序（app），我们抽象为：1func(in io.Reader, out io.Writer, args []string) 也就是说，Unix 中的 app1 params1 | app2 params2对应Go语言中是：1pipe( bind(app1, params1), bind(app2, params2) ) 其中，bind 函数实现如下：123456789func bind( app func(in io.Reader, out io.Writer, args []string), args []string) func(in io.Reader, out io.Writer) &#123; return func(in io.Reader, out io.Writer) &#123; app(in, out, args) &#125;&#125; 要理解bind函数，需要先理解“闭包”。Go语言中，应用程序以一个闭包的形式体现。如果你熟悉函数式编程，不难发现，这个bind函数其实就是所谓的柯里化（currying）。 pipe函数如下：123456789101112131415func pipe( app1 func(in io.Reader, out io.Writer), app2 func(in io.Reader, out io.Writer)) func(in io.Reader, out io.Writer) &#123; return func(in io.Reader, out io.Writer) &#123; pr, pw := io.Pipe() defer pw.Close() go func() &#123; defer pr.Close() app2(pr, out) &#125;() app1(in, pw) &#125;&#125; 要理解pipe函数，除了“闭包”外，需要知晓defer关键字和goroutine（go关键字）。defer语句会在函数退出时执行（无论是否发生了异常），通常用于资源的清理操作（比如关闭文件句柄等）。有了defer语句，Go语言中的错误处理代码显得非常优雅。在一个正常的函数调用前加上go关键字，就会使得该函数在新的goroutine中并行执行。理解了这些背景，这个pipe函数不难理解，无非是：先创建一个管道，让app1读入数据（in），并向管道的写入端（pw）输出，启动一个新goroutine，让app2从管道的读入端读取数据，并将处理结果输出（out）。这样得到的app就是app1和app2的组合了。 你甚至可以对多个app进行组合：123456789101112131415161718func pipe(apps ...func(in io.Reader, out io.Writer)) func(in io.Reader, out io.Writer) &#123; if len(apps) == 0 &#123; return nil &#125; app := apps[0] for i := 1; i &lt; len(apps); i++ &#123; app1, app2 := app, apps[i] app = func(in io.Reader, out io.Writer) &#123; pr, pw := io.Pipe() defer pw.Close() go func() &#123; defer pr.Close() app2(pr, out) &#125;() app1(in, pw) &#125; &#125; return app&#125; 我们举个比较实际的例子，假设我们有2个应用程序tar（打包）、gzip（压缩）：12func tar(io.Reader, out io.Writer, files []string)func gzip(in io.Reader, out io.Writer) 那么打包并压缩的代码是：1pipe( bind(tar, files), gzip )(nil, out) 通过对管道（pipeline）的模拟我们可以看出，Go语言对并行支持是非常强大的，这主要得益于Go的轻量级进程（goroutine）。 实例程序，帮助理解管道：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mainimport ( "io" "os" "bufio" "bytes" "fmt" "strconv")//bind函数主要是用来为pipe函数整合用的，通过将闭包将函数签名变成pipe所需的样子//返回一个函数闭包，将一个函数字面量app和字符串slice 传入其中func bind(app func(in io.Reader, out io.Writer, args []string), args []string) func(in io.Reader, out io.Writer) &#123; return func(in io.Reader, out io.Writer) &#123; app(in, out, args) &#125;&#125;//将两个函数插入到管道的中间，调用者只需调用pipe返回的函数字面量，并传入管道的首尾两端，即可实现管道//返回一个新的函数闭包func pipe(app1 func(in io.Reader, out io.Writer), app2 func(in io.Reader, out io.Writer)) func(in io.Reader, out io.Writer) &#123; return func(in io.Reader, out io.Writer) &#123; pr, pw := io.Pipe() defer pw.Close() go func() &#123; defer pr.Close() app2(pr, out) &#125;() app1(in, pw) &#125;&#125;//读取args slice的每个字符串，将其作为文件名，读取文件,并在文件的每一行首部加上行号，写入到out中//此处in没有使用到，主要是为了保证管道定义的一致性func app1(in io.Reader, out io.Writer, args []string) &#123; for _, v := range args &#123; //fmt.Println(v) file, err := os.Open(v) if err != nil &#123; continue &#125; defer file.Close() buf := bufio.NewReader(file) for i:=1; ;i++&#123; line, err := buf.ReadBytes('\n') if err != nil &#123; break &#125; linenum := strconv.Itoa(i) nline := []byte(linenum + " ") nline = append(nline, line...) out.Write(nline) &#125; &#125;&#125; 1234567891011121314151617181920212223//app2 主要是将字节流转化为大写,中文可能会有点问题，不过主要是演示用，重在理解思想//read from in, convert byte to Upper ,write the result to outfunc app2(in io.Reader, out io.Writer) &#123; rd := bufio.NewReader(in) p := make([]byte, 10) for &#123; n, _ := rd.Read(p) if n == 0 &#123; break &#125; t := bytes.ToUpper(p[:n]) out.Write(t) &#125;&#125;func main() &#123; args := os.Args[1:] for _, v := range args &#123; fmt.Println(v) &#125; p := pipe(bind(app1, args), app2) p(os.Stdin, os.Stdout)&#125; 参考文章原文-golang 并发设计模式(二)–管道模式1Go，基于连接与组合的语言（上）]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>pipe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[是用脚本分割Csv文件]]></title>
    <url>%2F2019%2F11%2F11%2Fpython-csv-split%2F</url>
    <content type="text"><![CDATA[首先安装panda 1pip install pandas 创建脚本:1234import pandas as pd rows = pd.read_csv("csvfile.csv", chunksize=5000000) # 每个文件的尺寸, 以及导入文件名for i, chuck in enumerate(rows): chuck.to_csv('out&#123;&#125;.csv'.format(i)) # 输出文件名 运行1python demo.py py挽救了我半小时的摸鱼时光生命]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>csv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转 Golang Http平滑重启实现]]></title>
    <url>%2F2019%2F11%2F04%2Fgo-http-grace-restart%2F</url>
    <content type="text"><![CDATA[服务端代码经常需要升级，对于线上系统的升级常用的做法是，通过前端的负载均衡（如nginx）来保证升级时至少有一个服务可用，依次（灰度）升级。 而另一种更方便的方法是在应用上做热重启，直接升级应用而不停服务。 主流程 监听信号（USR2） 收到信号时fork子进程（使用相同的启动命令），将服务监听的socket文件描述符传递给子进程 子进程监听父进程的socket，这个时候父进程和子进程都可以接收请求 子进程启动成功之后，父进程停止接收新的连接，等待旧连接处理完成（或超时） 父进程退出，升级完成 关键点 父进程将socket文件描述符传递给子进程可以通过命令行，或者环境变量等 子进程启动时使用和父进程一样的命令行，对于golang来说用更新的可执行程序覆盖旧程序 server.Shutdown()优雅关闭方法是go1.8的新特性 server.Serve(l)方法在Shutdown时立即返回，Shutdown方法则阻塞至context完成，所以Shutdown的方法要写在主goroutine中 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package mainimport ( "context" "errors" "flag" "log" "net" "net/http" "os" "os/exec" "os/signal" "syscall" "time")var ( server *http.Server listener net.Listener graceful = flag.Bool("graceful", false, "listen on fd open 3 (internal use only)"))func handler(w http.ResponseWriter, r *http.Request) &#123; time.Sleep(20 * time.Second) w.Write([]byte("hello world233333!!!!"))&#125;func main() &#123; flag.Parse() http.HandleFunc("/hello", handler) server = &amp;http.Server&#123;Addr: ":9999"&#125; var err error if *graceful &#123; log.Print("main: Listening to existing file descriptor 3.") // cmd.ExtraFiles: If non-nil, entry i becomes file descriptor 3+i. // when we put socket FD at the first entry, it will always be 3(0+3) f := os.NewFile(3, "") listener, err = net.FileListener(f) &#125; else &#123; log.Print("main: Listening on a new file descriptor.") listener, err = net.Listen("tcp", server.Addr) &#125; if err != nil &#123; log.Fatalf("listener error: %v", err) &#125; go func() &#123; // server.Shutdown() stops Serve() immediately, thus server.Serve() should not be in main goroutine err = server.Serve(listener) log.Printf("server.Serve err: %v\n", err) &#125;() signalHandler() log.Printf("signal end")&#125;func reload() error &#123; tl, ok := listener.(*net.TCPListener) if !ok &#123; return errors.New("listener is not tcp listener") &#125; f, err := tl.File() if err != nil &#123; return err &#125; args := []string&#123;"-graceful"&#125; log.Printf("exec Command: %s %v", os.Args[0], args) cmd := exec.Command(os.Args[0], args...) cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr // put socket FD at the first entry cmd.ExtraFiles = []*os.File&#123;f&#125; return cmd.Start()&#125;func signalHandler() &#123; ch := make(chan os.Signal, 1) signal.Notify(ch, syscall.SIGINT, syscall.SIGTERM, syscall.SIGUSR2) for &#123; sig := &lt;-ch log.Printf("signal: %v", sig) // timeout context for shutdown ctx, _ := context.WithTimeout(context.Background(), 20*time.Second) switch sig &#123; case syscall.SIGINT, syscall.SIGTERM: // stop log.Printf("stop") signal.Stop(ch) server.Shutdown(ctx) log.Printf("graceful shutdown") return case syscall.SIGUSR2: // reload log.Printf("reload") err := reload() if err != nil &#123; log.Fatalf("graceful restart error: %v", err) &#125; server.Shutdown(ctx) log.Printf("graceful reload") return &#125; &#125;&#125; 文章原文]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>http</tag>
        <tag>grace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang 通过 Context 控制并发的应用场景]]></title>
    <url>%2F2019%2F10%2F25%2Fgo-context%2F</url>
    <content type="text"><![CDATA[golang 里出现多 goroutine 的场景很常见, 最常用的两种方式就是 WaitGroup 和 Context, 今天我们了解一下 Context 的应用场景 使用场景场景一: 多goroutine执行超时通知并发执行的业务中最常见的就是有协程执行超时, 如果不做超时处理就会出现一个僵尸进程, 这累计的多了就会有一阵手忙脚乱了, 所以我们要在源头上就避免它们 看下面这个示例:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package mainimport ( "context" "fmt" "time")/**同一个content可以控制多个goroutine, 确保线程可控, 而不是每新建一个goroutine就要有一个chan去通知他关闭有了他代码更加简洁*/func main() &#123; fmt.Println("run demo \n\n\n") demo()&#125;func demo() &#123; ctx, cancel := context.WithTimeout(context.Background(), 9*time.Second) go watch(ctx, "[线程1]") go watch(ctx, "[线程2]") go watch(ctx, "[线程3]") index := 0 for &#123; index++ fmt.Printf("%d 秒过去了 \n", index) time.Sleep(1 * time.Second) if index &gt; 10 &#123; break &#125; &#125; fmt.Println("通知停止监控") // 其实此时已经超时, 协程已经提前退出 cancel() // 防止主进程提前退出 time.Sleep(3 * time.Second) fmt.Println("done")&#125;func watch(ctx context.Context, name string) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf("%s 监控退出, 停止了...\n", name) return default: fmt.Printf("%s goroutine监控中... \n", name) time.Sleep(2 * time.Second) &#125; &#125;&#125; 使用 context.WithTimeout() 给文本流设置一个时间上限, 结合 for+select 去接收消息. 当执行超时,或手动关闭都会给 &lt;-ctx.Done() 发送消息,而且所有使用同一个 context 都会收到这个通知, 免去了一个一个通知的繁琐代码 场景二: 类似web服务器中的session比如在php中(没用swoole扩展), 一个请求进来, 从 $_REQUEST $_SERVER 能获取到的是有关这一条请求的所有信息, 哪怕是使用全局变量也是给这一个请求来服务的, 是线程安全的 但是 golang 就不一样了, 因为程序本身就能起一个 web sever, 因此就不能随便使用全局变量了, 不然就是内存泄露警告. 但是实际业务当中需要有一个类似session 的东西来承载单次请求的信息, 举一个具体的例子就是: 给每次请求加一个 uniqueID 该如何处理? 有了这个 uniqueID, 请求的所有日志都能带上它, 这样排查问题的时候方便追踪一次请求发生了什么 如下:1234567891011121314151617181920212223func demo2() &#123; pCtx, pCancel := context.WithCancel(context.Background()) pCtx = context.WithValue(pCtx, "parentKey", "parentVale") go watch(pCtx, "[父进程1]") go watch(pCtx, "[父进程2]") cCtx, cCancel := context.WithCancel(pCtx) go watch(cCtx, "[子进程1]") go watch(cCtx, "[子进程2]") fmt.Println(pCtx.Value("parentKey")) fmt.Println(cCtx.Value("parentKey")) time.Sleep(10 * time.Second) fmt.Println("子进程关闭") cCancel() time.Sleep(5 * time.Second) fmt.Println("父进程关闭") pCancel() time.Sleep(3 * time.Second) fmt.Println("done")&#125; 最开始的 context.WithCancel(context.Background()) 中 context.Background() 就是一个新建的 context, 利用 context 能继承的特性,可以将自己的程序构建出一个 context 树, context 执行 cancel() 将影响到当前 context 和子 context, 不会影响到父级. 同时 context.WithValue 也会给 context 带上自定义的值, 这样 uniqueID 就能轻松的传递了下去, 而不是一层层的传递参数, 改func什么的 对于 context 很值得参考的应用有: Gin logrus Context 相关 func 和接口继承 context 需要实现如下四个接口12345678910type Context interface &#123; Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct&#123;&#125; Err() error Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 当使用的时候不需要实现接口, 因为官方包里已经基于 emptyCtx 实现了一个, 调用方法有 1234567891011121314var ( background = new(emptyCtx) todo = new(emptyCtx))// 这个是最初始的ctx, 之后的子ctx都是继承自它func Background() Context &#123; return background&#125;// 不清楚context要干嘛, 但是就得有一个ctx的用这个func TODO() Context &#123; return todo&#125; 继承用的函数1234func WithCancel(parent Context) (ctx Context, cancel CancelFunc)func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)func WithValue(parent Context, key, val interface&#123;&#125;) Context WithCancel 返回一个带 cancel 函数的ctx, WithDeadline 在到达指定时间时自动执行 cancel() WithTimeout 是 WithDeadline的壳子, 区别就是这个函数是多少时间过后执行 cancel 123func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125; WithValue 继承父类ctx时顺便带上一个值]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>context</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 部署 K8s]]></title>
    <url>%2F2019%2F06%2F17%2Fk8s-install-centos7%2F</url>
    <content type="text"><![CDATA[都是走的国内镜像源 关闭 selinux12setenforce 0 #实时动态关闭 selinuxsed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config #禁止重启后自动开启 关闭交换分区12swapoff -a #实时动态关闭交换分区sed -i &apos;/ swap / s/^/#/&apos; /etc/fstab #禁止重启后自动开启 网络配置文件123456789cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1vm.swappiness=0EOFmodprobe br_netfilter #执行该命令 如果不执行就会在应用k8s.conf时出现加载错误sysctl -p /etc/sysctl.d/k8s.conf #应用配置文件 yum换国内源12345cd /etc/yum.repos.d &amp;&amp; \sudo mv CentOS-Base.repo CentOS-Base.repo.bak &amp;&amp; \sudo wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo &amp;&amp; \yum clean all &amp;&amp; \yum makecache 配置k8s资源的下载地址1234567891011cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装依赖1yum install -y docker kubelet kubeadm kubectl docker换源12345678mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123;&quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125;EOFservice docker restart 开机启动123systemctl disable firewalld.service &amp;&amp; systemctl stop firewalld.service systemctl enable docker &amp;&amp; systemctl start dockersystemctl enable kubelet &amp;&amp; systemctl start kubelet 下载k8s依赖镜像获取依赖的镜像1kubeadm config images list 国内用户通过阿里云镜像下载k8s依赖组件12345kubeadm config images list |sed -e &apos;s/^/docker pull /g&apos; -e &apos;s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/google_containers#g&apos; |sh -xdocker images |grep registry.cn-hangzhou.aliyuncs.com/google_containers |awk &apos;&#123;print &quot;docker tag &quot;,$1&quot;:&quot;$2,$1&quot;:&quot;$2&#125;&apos; |sed -e &apos;s#registry.cn-hangzhou.aliyuncs.com/google_containers#k8s.gcr.io#2&apos; |sh -xdocker images |grep registry.cn-hangzhou.aliyuncs.com/google_containers |awk &apos;&#123;print &quot;docker rmi &quot;, $1&quot;:&quot;$2&#125;&apos; |sh -x 主节点初始化Kubernetes v1.14.31kubeadm init --kubernetes-version=1.14.3 执行成功后出现1234567891011121314To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.31.120:6443 --token 6nelb5.lrc5qbs0k3v64eln \ --discovery-token-ca-cert-hash sha256:c55a113114d664133685430a86f2e39f40e9df6b12ad3f4d65462fd372079e97 node节点启动12kubeadm join 192.168.31.120:6443 --token 6nelb5.lrc5qbs0k3v64eln \ --discovery-token-ca-cert-hash sha256:c55a113114d664133685430a86f2e39f40e9df6b12ad3f4d65462fd372079e97 就是初始化后的最后一条命令 主节点执行：1234[root@localhost ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONlocalhost.localdomain NotReady master 40m v1.14.3miwifi-r3-srv NotReady &lt;none&gt; 3m48s v1.14.3 状态还是notReady 查看文档 https://kubernetes.io/docs/concepts/cluster-administration/addons/ 这里选了 weave 插件文档： https://www.weave.works/docs/net/latest/kubernetes/kube-addon/执行命令1kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &apos;\n&apos;)&quot; 稍微等几分钟就可以看到正常了1234[root@localhost ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONlocalhost.localdomain Ready master 49m v1.14.3miwifi-r3-srv Ready &lt;none&gt; 12m v1.14.3 kubeadm token 过期的情况kubeadm join 用到的token有效期是24h 生成 token, 查看token 12345$ kubeadm token createrugi2c.bb97e7ney91bogbg$ kubeadm token listTOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPSrugi2c.bb97e7ney91bogbg 23h 2019-06-18T22:28:11+08:00 authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-token 生成证书1openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos; 新token加入12kubeadm join 192.168.31.120:6443 --token rugi2c.bb97e7ney91bogbg \ --discovery-token-ca-cert-hash sha256:c55a113114d664133685430a86f2e39f40e9df6b12ad3f4d65462fd372079e97 搭建教程部署node节点]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8s 安装 Minikube]]></title>
    <url>%2F2019%2F05%2F14%2Fk8s-minikube%2F</url>
    <content type="text"><![CDATA[本地快速装一个微型的kubernetes环境, 翻墙的苦谁能懂? mac 本地安装minikube环境环境需求: kubectl 本地做命令行控制用, 所有的命令操作都是通过它 vittualBox v5.1 + 更新到最新版本就对了 minikube 在本地搭建测试环境 翻墙有困难的可以参考一下这个 https://yq.aliyun.com/articles/221687 安装 kubectl1➜ brew install kubectl 下载最新 minikube 不建议使用brew安装, 首先版本不会是最新, 再者会出现莫名其妙的问题123➜ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 &amp;&amp; \ chmod +x minikube &amp;&amp; \ sudo mv minikube /usr/local/bin/ 默认 start 时运行的virtualBox 去官网下个最新的就行 启动, 最好把docker镜像指定到国内12345678910111213141516171819202122232425➜ ~ minikube start --registry-mirror=https://registry.docker-cn.com😄 minikube v1.0.1 on darwin (amd64)💿 Downloading Minikube ISO ... 142.88 MB / 142.88 MB [============================================] 100.00% 0s🤹 Downloading Kubernetes v1.14.1 images in the background ...🔥 Creating virtualbox VM (CPUs=2, Memory=2048MB, Disk=20000MB) ...📶 &quot;minikube&quot; IP address is 192.168.99.103🐳 Configuring Docker as the container runtime ...🐳 Version of container runtime is 18.06.3-ce⌛ Waiting for image downloads to complete ...✨ Preparing Kubernetes environment ...💾 Downloading kubeadm v1.14.1💾 Downloading kubelet v1.14.1🚜 Pulling images required by Kubernetes v1.14.1 ...🚀 Launching Kubernetes v1.14.1 using kubeadm ...⌛ Waiting for pods: apiserver proxy etcd scheduler controller dns🔑 Configuring cluster permissions ...🤔 Verifying component health .....💗 kubectl is now configured to use &quot;minikube&quot;🏄 Done! Thank you for using minikube!➜ ~ kubectl cluster-infoKubernetes master is running at https://192.168.99.103:8443KubeDNS is running at https://192.168.99.103:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use &apos;kubectl cluster-info dump&apos;. 如果Minikube ISO存在墙的问题, 就把iso下载后放到 ~/.minikube/cache/iso/下 这时Mac上的docker不能用docker for Mac提供的了, 而是宿主机里面的docker, 切换命令为:1➜ eval $(minikube docker-env) 撤销更改1➜ eval $(minikube docker-env -u) 加载后台控制面板, 稍等一会, 自动打卡后台界面1➜ minikube dashboard 部署第一个应用命令行部署创建node.js 应用创建文件 server.js123456789var http = require('http');var handleRequest = function(request, response) &#123; console.log('Received request for URL: ' + request.url); response.writeHead(200); response.end('Hello World! V1');&#125;;var www = http.createServer(handleRequest);www.listen(3000); 运行1node server.js // 访问地址 http://localhost:3000 创建docker镜像123456FROM node:8.10.0EXPOSE 3000COPY server.js .CMD ["node", "server.js"] 构建镜像1➜ docker build -t hello-node:v1 . 如果出现Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 说明你忘了执行 eval $(minikube docker-env)kube用的 docker 和你本地用的 docker 是两个位置, kube的在虚拟机里运行 创建 deployment有了镜像就具备创建pod的条件, 通常来说不用直接创建 pod, 而是创建 deployment 或者 replication controller, 由他们来负责管理服务的运行, 规模缩放, 自动重启等等这些操作, 就单个pod来说是可以随时被销毁的, 不能作为稳定服务的保证 123➜ kubectl run hello-node --image=hello-node:v1 --port=3000或➜ kubectl create deployment hello-node --image=hello-node:v1 查看当前deployment123➜ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGEhello-node 1/1 1 1 8m8s ready 1/1 说明已经准备就绪了 查看 pod123➜ hellonode git:(master) ✗ kubectl get podsNAME READY STATUS RESTARTS AGEhello-node-5c58cb6dd4-h65fx 1/1 Running 0 8m40s 从这两条信息就能看出来, 每个pod都是带随机字符串的, 并不打算给人去操作, 我们主要专注在deployment和 service 的搭建 查看 deployment 描述123456789101112131415161718192021222324252627282930313233➜ kubectl describe deployments/hello-nodeName: hello-nodeNamespace: defaultCreationTimestamp: Mon, 13 May 2019 14:17:03 +0800Labels: run=hello-nodeAnnotations: deployment.kubernetes.io/revision: 1Selector: run=hello-nodeReplicas: 1 desired | 1 updated | 1 total | 1 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: run=hello-node Containers: hello-node: Image: hello-node:v1 Port: 3000/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: hello-node-5c58cb6dd4 (1/1 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set hello-node-5c58cb6dd4 to 1 这里是对deployment的概览, Pod Template: 下就是每个pods的配置, 之后对部署的扩容都是基于这个去复制 到目前为止我们创建了deployment 而且也自动生成pod了, 可是服务并不能被访问到, 为什么? 因为端口没有对外暴露出来, 所以有了下一步 创建serviceservice 就是用来对我暴露服务的东西, 所有的 pod 都是在内网通信, 外部访问就得让 service 这层代理去转发过去, --type=LoadBalancer 就是指定转发为负载均衡模式, kubectl create service -h 查看更多, 这里不细讲 创建service123➜ kubectl expose deployment hello-node --type=LoadBalancer或➜ kubectl expose deployment hello-node --type=LoadBalancer --port=3000 // 这里指定端口 查看1234➜ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhello-node LoadBalancer 10.111.18.151 &lt;pending&gt; 3000:31349/TCP 3skubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 3d 详细信息123456789101112131415➜ kubectl describe services hello-node Name: hello-nodeNamespace: defaultLabels: run=hello-nodeAnnotations: &lt;none&gt;Selector: run=hello-nodeType: LoadBalancerIP: 10.111.18.151Port: &lt;unset&gt; 3000/TCPTargetPort: 3000/TCPNodePort: &lt;unset&gt; 31349/TCPEndpoints: 172.17.0.7:3000Session Affinity: NoneExternal Traffic Policy: ClusterEvents: &lt;none&gt; NodePort 就是绑定在节点的那个端口上, 直接访问节点ip就行, 也可以用minikube命令 minikube service hello-node 自动帮你打开本地地址 扩展示例线上肯定是有这种动态扩容的情况, 而且多实例之间滚动升级也不会停止服务12345678➜ kubectl scale deployments/hello-node --replicas=4deployment.extensions/hello-node scaled➜ hellonode git:(master) ✗ kubectl get podsNAME READY STATUS RESTARTS AGEhello-node-5c58cb6dd4-d2qq9 1/1 Running 0 18shello-node-5c58cb6dd4-h65fx 1/1 Running 0 51mhello-node-5c58cb6dd4-jlzjw 1/1 Running 0 18shello-node-5c58cb6dd4-vmx4f 1/1 Running 0 18s 更新应用重新构建一个node的镜像service.js123456789var http = require('http');var handleRequest = function(request, response) &#123; console.log('Received request for URL: ' + request.url); response.writeHead(200); response.end('Hello World! V2');&#125;;var www = http.createServer(handleRequest);www.listen(3000); 1➜ docker build -t hello-node:v2 . 设置 deployment 使用新镜像1➜ kubectl set image deployment/hello-node hello-node=hello-node:v2 查看每个pod的具体情况1➜ kubectl describe pods 再访问刚才的地址就能看到改变了 清除资源12➜ kubectl delete service hello-node➜ kubectl delete deployments hello-node 经过上面一套操作下来, 应该也对k8s有了一个大致的印象了, 毕竟光看实践才是检验真理的唯一标准, 但是如果部署一个服务这样一个命令一个命令的敲是很要命的, 而且服务器这玩意, 轻易不会动, 时间一长就容易忘, 因此用配置文件去启动更加合理 通过 yaml 启动如下: test-service.yaml123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Servicemetadata: name: test-service labels: version: v2 run: hello-node app: test-servicespec: type: LoadBalancer ports: - port: 3001 targetPort: 3000 protocol: TCP selector: app: test-service---apiVersion: apps/v1kind: Deploymentmetadata: name: test-service labels: app: test-servicespec: replicas: 2 selector: matchLabels: app: test-service template: metadata: labels: app: test-service spec: containers: - name: node-pod image: hello-node:v2 imagePullPolicy: IfNotPresent ports: - containerPort: 3000 执行12➜ kubectl create -f test-service.yaml➜ minikube service test-service 这样通过配置文件就能启动了, 配置文件里里的字段后续我们再详细的讲一下 删除kubectl delete -f test-service.yaml 代码地址 相关资料带你理解Kubernetes，部署一个Node应用Kubernetes的三种外部访问方式：NodePort、LoadBalancer 和 IngressMinikube - Kubernetes本地实验环境Kubernetes之kubectl常用命令replication controller与deployment的区别Kubenetes里pod和service绑定的实现方式Kubernetes创建资源对象yaml文件例子kubernetes/minikube github]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker for Mac 部署 Kubernetes]]></title>
    <url>%2F2019%2F05%2F06%2Fk8s-install-docker%2F</url>
    <content type="text"><![CDATA[docker for mac 安装kubernetes本来是很方便的, 但是国内玩家要折腾一下, 因为 gcr.io 这个域被墙了… 目前来看前辈们已经把坑给淌的差不多了, 我老早的时候也被折腾的头秃, 这里就做个总结 通过代理翻墙下载镜像这个方法相对来说一劳永逸, 缺点是每个月有vpn的花费, 我代理用的shadowsockets, 就拿这个来举例: 首先安装1brew install privoxy 添加配置: 1vi /usr/local/etc/privoxy/config 配置内容:12listen-address 0.0.0.0:8118forward-socks5 / localhost:1080 . 监听本地8118端口, 转发到 localhost:1080, 这也是ss的客户端的转发端口 启动:1brew services start privoxy 转发部分完成, 接下来在 docker for mac配置 docker for mac &gt; preferences &gt; Proxies &gt; 点击 Manual proxy configuration Web Server(HTTP) 和 Secure Web Server (HTTPS) 都填入 http://{你机器IP}:8118 比如: ‘http://192.168.110.203:8118&#39; 不能用 127.0.0.1, 因为 docker for mac 启动后, docker 是运行在一个虚拟机中,而不是macOS下, 因此这个地址代表的意义不一样 点保存, 这样就能正常安装k8s了, 可以通过活动监视器看一下他们的流量是否正常 教程来源 自己预先加载一套镜像来找个目录, 新建 images.properties12345678910k8s.gcr.io/pause-amd64:3.1=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1k8s.gcr.io/kube-controller-manager-amd64:v1.10.3=registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager-amd64:v1.10.3k8s.gcr.io/kube-scheduler-amd64:v1.10.3=registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler-amd64:v1.10.3k8s.gcr.io/kube-proxy-amd64:v1.10.3=registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64:v1.10.3k8s.gcr.io/kube-apiserver-amd64:v1.10.3=registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver-amd64:v1.10.3k8s.gcr.io/etcd-amd64:3.1.12=registry.cn-hangzhou.aliyuncs.com/google_containers/etcd-amd64:3.1.12k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.8=registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-dns-sidecar-amd64:1.14.8k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.8=registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-dns-kube-dns-amd64:1.14.8k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.8=registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.3=registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.8.3 新建脚本: kubernetes.sh12345678910111213141516171819#/bin/bashfile="./images.properties"if [ -f "$file" ]then echo "$file found." while IFS='=' read -r key value do #echo "$&#123;key&#125;=$&#123;value&#125;" docker pull $&#123;value&#125; docker tag $&#123;value&#125; $&#123;key&#125; docker rmi $&#123;value&#125; done &lt; "$file"else echo "$file not found."fi 运行就行 教程来源k8s-docker-for-mac 找个gcr.io的国内镜像这个是利用了dockerHub 因为都是国外的, 先让dockerHub给build一下, 然后直接拉dockerHub的镜像来迂回一下 Google Container Registry(gcr.io) 中国可用镜像(长期维护)gcr.io_mirror基于Docker for macOS的Kubernetes本地环境搭建与应用部署]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter 对Tcp进行压测]]></title>
    <url>%2F2019%2F04%2F30%2Ftools-jmeter%2F</url>
    <content type="text"><![CDATA[jmeter是个好工具, 跨平台, 有GUI, 简单易用, 扩展多 安装本地环境为macOS Mojave 10.14.4 本地需要安装java8jmeter官方下载地址jmeter插件下载 当前下载的jmeter版本为 5.1.1解压下载之后, 运行命令:1sh ~/Downloads/apache-jmeter-5.1.1/bin/jmeter 就运行起来了 进行tcp压测首先创建Thread Group 注意几个关键点: Number of Threads (users) 创建进程组, 相当于多少并发 Ramp-Up Period (in seconds) 设定的并发值在多少秒内到达预期, 模拟自然流量 Loop Count 每个进程组循环多少次 Loop Count * Number of Threads 就是整体请求数量了 创建tcp Sampler 这篇文章是使用最基本的文字tcp传输 看图说话, TCP classname默认为: org.apache.jmeter.protocol.tcp.sampler.TCPClientImpl, 可以直接从 Text to send 中传入文本传文本的时候一定要输入之后加一个回车,写\n都不管用, 必须 是回车, 它是自动转换的, 不然会造成数据找不到终止断点 如果使用 org.apache.jmeter.protocol.tcp.sampler.BinaryTCPClientImpl 则需要在 End of line byte value 里面传值, 通常是10且 Text to send 传的是16进制数据 创建 summary report 用于做统计表格 创建 view results tree 用于查看请求数据返回数据 安装cpu/内存监控插件5.1.1 版本的和之前搜的有些不一样, 现在有了一个内置的扩展商店 扩展下载地址 Download plugins-manager.jar and put it into lib/ext directory, then restart JMeter. 看到这句话没? 点就行了, 然后把它放到jmeter目录 lib/ext下,重启jmeter就能看到了 点进去搜索 PerfMon ,就是我们要找的了, 点击安装 , 从插件简介里也能看到文档地址 在文档中找到 Server Agent的下载地址 在被测服务器中安装 Server Agent , linux 直接运行 serverAgent.sh 默认端口为 4444 添加监控:点 Add Row 添加目标服务器的ip和端口就行, 端口默认4444 以上就是一套简单的tcp压测测试了 原文地址]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Php开发过程中不常碰到的error (2.28更新)]]></title>
    <url>%2F2019%2F02%2F28%2Fphp-unsual-mistakes%2F</url>
    <content type="text"><![CDATA[这里做一些备注,以防再次碰到 url 当中的参数有 &amp;timestamp=1234567890这样的字段会被转义成xtamp=1234567890这个不仅存在于页面解析当中,当使用 curl 请求时拼接的参数有这种格式的也会发生转义解决方法有两个: 把 timestamp 这个参数放在 urlQuery 的最前面, ?timestamp=1234567890 这样避免出现 &amp;time发生转义的情况 将&amp;用&amp;amp;来代替 Automatically populating $HTTP_RAW_POST_DATA is deprecated and will be removed in a future version.出现这句话通常说明你在用的 php 版本是5.6.而且在php&lt;=5.6的时候,进行 application/json格式的 post 提交会把数据放在$HTTP_RAW_POST_DATA这个系统变量里面,在php&gt;=7的时候这个变量被移除了,统统归总到php://input这里解决方法: 根据系统提示的走: Although that indeed would be technically impossible (as $HTTP_RAW_POST_DATA is populated in the bootstrapping phase of the PHP process) allow one to override the setting by means of calling ini_set. 要确保自己的系统中没有使用 HTTP_RAW_POST_DATA这个变量,直接在php.ini里面禁掉它的设置,但是容易出现系统中又打开的情况(在框架中很常见) 改一下自己的提交方式, 使用 application/form-data或者application/x-www-form-urlencoded这种格式的提交, 然后在后端接收数据的时候再转成自己需要的格式(通常是数组) 参考资料 Exception ‘yii\db\Exception’ with message ‘SQLSTATE[HY000] [2002] No such file or directory’这种情况出现在平时运行的好好的, 但是突然换 cli 模式后这个配置就出问题了,原因在当 host=localhost时走的是 unix:socket 链接, 当host=127.0.0.1走的是 tcp 链接,这在php-fpm和php-cli中有点区别,尤其是本地没有安装 mysql 的时候解决方法有三种: 将本地链接配置统一成 127.0.0.1 查看 MySQL 中的user表, host=localhost和host=127.0.0.1是不是用的同一个账号密码 配置php.ini文件中的pdo_mysql.default_socket= 写上完整的 socket 路径以上三种方法都可以试一下参考资料 常驻内存时发生的事情这个是 phper 很少碰到但是很常见的情况, 比如用 swoole 启动了一个常驻进程的服务, 那么就一定要小心使用静态变量,在同步模式下会发生变量污染, 还有就是 redis,mysql 这类的链接,你会发现长时间静置以后就会出现一些摸不着头脑的问题, 这种情况不妨想一下是不是 server 端回收了这个 socket,因此在 client 端怎么都写入不进去. 还有就是 php 在读取消息的时候,出现消息过长的情况,那么就要考虑EOF终止符的问题了… 单次 http 每一次请求都是全新的代码, 不用自己考虑 gc 的问题, 但是在常驻内存的时候,这些就是一个个的大坑了 mysql has gone away产生这个错误的主要原因是 mysql server 端断开了链接, client 端还拿着这个句柄去请求,解决方式有两种: show global variables like &#39;%timeout&#39;; 查看 wait_timeout 的时长,适当的调长一点, 这种方法治标不治本,而且有隐患 12mysql&gt; set global wait_timeout=10;mysql&gt; show global variables like 'wait_timeout'; 使用 mysql 之前需要 mysql_ping() 一下, 如果出现断开的错误就启动重连机制 js 和 php 交互传中文参数的编解码问题之前碰到了问题是:在 php 端 urlencode 的值为:1orderid%3D21111111110001954%26pid%3D257742%26reason%3D%E4%B8%AA%E4%BA%BA%E6%96%B9%E9%9D%A2%E5%8E%9F%E5%9B%A0_%E4%BD%BF%E7%94%A8%E7%BA%A2%E5%8C%85%E9%87%8D%E6%96%B0%E4%B8%8B%E5%8D%95%26token%3D041d9e5575f480b7bfd58b09bd14ab1c7ee9e9594f2fcdb9f0e3e39fc634b48f 需要 urldecode 一次 而在 js 端的结果是:1orderid%3D21111111110002170%26pid%3D257742%26reason%3D%25E4%25B8%25AA%25E4%25BA%25BA%25E6%2596%25B9%25E9%259D%25A2%25E5%258E%259F%25E5%259B%25A0_%25E4%25B8%25AA%25E4%25BA%25BA%25E8%25BA%25AB%25E4%25BD%2593%25E5%258E%259F%25E5%259B%25A0%26token%3D041d9e5575f480b7bfd58b09bd14ab1c7ee9e9594f2fcdb9f0e3e39fc634b48f 需要 urldecode 两次 查阅资料后:12345678910111213在后端是PHP程序的情况下，保持前端Javascript和PHP之间传值的统一编码可以使用以下函数进行处理： WEB前端JavaScript 编码：escape(encodeURI(string)) 解码：unescape(decodeURI(string)) WEB后端Php 编码：urlencode(string) 解码：urldecode(urldecode(string)) 为什么要encodeURI(url)两次才不会出现乱码？ PHP中rawurlencode和urlencode、JS中encodeURI与encodeURIComponent 的区别rawurlencode遵守是94年国际标准备忘录RFC 1738 urlencode实现的是传统做法，和上者的主要区别是对空格的转义是’+’而不是’%20’javascript的encodeURL也是94年标准，而javascript的escape是另一种用”%xxx”标记unicode编码的方法。推荐在PHP中使用用rawurlencode。弃用urlencode 样例source:超级无敌的人sadha sajdh数据样本sdls fhejrthcxzb.file.jpeg PHP urlencode:%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E7%9A%84%E4%BA%BAsadha+sajdh%E6%95%B0%E6%8D%AE%E6%A0%B7%E6%9C%ACsdls+fhejrthcxzb.file.jpeg PHP rawurlencode:%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E7%9A%84%E4%BA%BAsadha%20sajdh%E6%95%B0%E6%8D%AE%E6%A0%B7%E6%9C%ACsdls%20fhejrthcxzb.file.jpeg Javascript encodeURI|encodeURIComponent:%E8%B6%85%E7%BA%A7%E6%97%A0%E6%95%8C%E7%9A%84%E4%BA%BAsadha%20sajdh%E6%95%B0%E6%8D%AE%E6%A0%B7%E6%9C%ACsdls%20fhejrthcxzb.file.jpeg Javascript escape:%u8D85%u7EA7%u65E0%u654C%u7684%u4EBAsadha%20sajdh%u6570%u636E%u6837%u672Csdls%20fhejrthcxzb.file.jpeg 帖子原文 在前端还有个问题就是, js 的 encodeURIComponent 和 encodeURI 都不会转换 _-.!~*&#39;()# 这些保留字符, 而在后端的rawurlencode 则是会转换的, 因此需要前端单独把这几个给拎出来, 如下:12"*".charCodeAt(0) // 42String.fromCharCode(42) // * 这里有张图说的很明白图片来源 关于出现 &lt;U+200B&gt; 这种 zero-width space 字符如果出现 mb_substr 这类操作的时候, 会出现字数判断错误的问题, 这个有时候很难排查, 因为在 win 上,使用命令行或者 linux 上用cat命令是看不到字符间是有 &lt;U+200B&gt; 的, 如下: 这玩意儿出现的场景就是: 在前端输入框中输入几个字, 然后复制粘贴. 这样尽管看起来之间没有空格, 但是其中还是插入了这个字符这个就是 zero-width space 零宽空格, 处理的办法也很简单, 前端传值之前给过滤一下, 比如 https://stackoverflow.com/questions/7055600/u200b-zero-width-space-characters-in-my-js-code-where-did-they-come-from 或 https://codeday.me/bug/20171122/97765.html 后端 php 处理的话和这个不一样, 使用 utf-8 的处理方式, 可以参考这篇文章 特殊字符的删除办法与原理 替换这种编码123$value = str_replace("\xe2\x80\x8b", '', $value);$value = str_replace("\xe2\x80\x8c", '', $value);$value = str_replace("\xe2\x80\x8d", '', $value); 编码对照如下: mac 设置crontab -e ： “/usr/bin/vi” exited with status 1输入以下命令1234export EDITOR=vimsudo touch /etc/crontabcrontab -ecrontab -l 把默认编辑器从 vi 改成 vim 原文 出现: The “https://bower.herokuapp.com/packages/jquery&quot; file could not be downloaded (HTTP/1.1 502 Bad Gateway)yii2 更新的时候静态资源出现问题, 执行 composer global require &quot;fxp/composer-asset-plugin:~1.4.4&quot; 问题来源 出现: Jquery UI 1.11.4 and jquery 3.0 的版本兼容问题这个是在部署 adminLTE + rbac 时候遇上的, 打开 /admin/menu/create 会报 Jquery UI error - f.getClientRects is not a function 错误 解决方法:配置文件: config/web.php1234567891011121314151617... 'components' =&gt; [ ... //静态资源 'assetManager' =&gt; [ ... 'assetMap' =&gt; [ 'jquery.js' =&gt; 'https://cdn.bootcss.com/jquery/2.2.4/jquery.min.js', // 'jquery.min.js' =&gt; 'https://cdn.bootcss.com/jquery/2.2.4/jquery.min.js',// 'jquery.js' =&gt; '@web/js/jquery/jquery.js',// 'jquery.min.js' =&gt; '@web/js/jquery/jquery.js', ], ... ], ... ]... 把相应的 jquery 替换成 v2.2.4 解决问题来源 macOS brew安装php7.1 以及swoole扩展brew改版后内核集成了php, 所以可以直接安装安装php1brew install php@7.1 按提示把12echo 'export PATH="/usr/local/opt/php@7.1/bin:$PATH"' &gt;&gt; ~/.zshrcecho 'export PATH="/usr/local/opt/php@7.1/sbin:$PATH"' &gt;&gt; ~/.zshrc 这些放到你本地命令行配置里面, 然后生成一个软链1brew link php@7.1 --force 安装扩展就得使用pecl工具了12cd /usr/local/opt/php@7.1 # 执行完 brew link 之后就按软链的来, 这样的好处就是不用记小版本号, 路径短pecl install swoole # 提示 'openssl/ssl.h' file not found 就是你安装的时候别选 ssl支持就行 如果提示 No releases available for package “pecl.php.net/swoole”参考 执行 ‘pecl install swoole’之后，遇到的一些坑 , 按提示一步步走应该没问题 安装完毕之后需要变一下配置12345php -i | grep .ini...Loaded Configuration File =&gt; /usr/local/etc/php/7.1/php.ini //当前加载的配置文件路径...cd /usr/local/etc/php/7.1 先删除 php.ini 里面第一行的 extension=swoole.so 改成这个so文件的真实路径, 推荐放到隔壁的 conf.d 目录底下然后php -m | grep sw 可以看一下了安装其他扩展也是按这个路数来 出现 Connection reset by peer 报错这是个tcp链接上的错误, 意味着 链接过程中读或者写出现异常, 出现的原因: AB两端, A端关闭了链接, B端仍在发送, 则抛异常 AB两端, A退出但没关闭链接, 则B在读的时候抛异常 排查: 先看看server端是不是对包大小进行了限制, buffer分配是否足够 是不是程序链接到上限了, 被服务器误杀 防火墙问题 Warning: preg_match() [function.preg-match]: Compilation failed: PCRE does not support \L, \l, \N, \U, or \u atphp正则匹配中文字符的时候, 使用 /^[\u4e00-\u9fa5]+$/ 这一条就会报上面的错误, 正确的写法应该是:123456$str = "php编程";if (preg_match("/^[\x&#123;4e00&#125;-\x&#123;9fa5&#125;]+$/u",$str)) &#123;print("该字符串全部是中文");&#125; else &#123;print("该字符串不全部是中文");&#125; php preg_match 正则匹配中文 php匹配 UTF-8 with DOM 的字符这个和上面的匹配中文是一起出现的, win上使用 UTF-8 格式的txt文件在linux上打开就会变成 UTF-8 with DOM 这个类型, 文件内容中会存在dom头, 从而干扰到一些判断, 比如正则匹配解决办法也简单, 去掉就行1234567// 简单的将win上的txt文件转成utf-8格式function toUTF8($str)&#123; $type = mb_detect_encoding($str, array("ASCII","UTF-8","GB2312","GBK","BIG5")); $result = iconv($type, 'UTF-8//IGNORE', $str); // 防止UTF-8 with BOM 的情况 return trim($result, "\xEF\xBB\xBF");&#125; 不过 utf-8 with dom 对php来说是个隐患, 因为php没有对这块的处理, 会出现ZERO WIDTH NO-BREAK SPACE这样的问题, 有数据但是不会在页面输出 参考:PHP UTF-8的 BOM 问题解决]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>debug</tag>
      </tags>
  </entry>
</search>
